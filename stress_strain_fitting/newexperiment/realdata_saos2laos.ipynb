{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本文件为真实数据拟合的PI-GRU模型，用于预测材料的力学性能。LAOS预测, 使用不同的本构模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random, genfromtxt\n",
    "from IPython.display import display\n",
    "from matplotlib import rc\n",
    "from matplotlib.pyplot import figure\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.ticker as mticker\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 导入必要的库\n",
    "import xgboost as xgb\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/redfu/work/Constitutive_Equation/stress_strain_fitting/newexperiment\n",
      "Using GPU: NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(current_directory)\n",
    "\n",
    "# 检查是否有可用的 GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # 使用 GPU\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # 使用 CPU\n",
    "    print(\"No GPU available, using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系统已安装 Arial 字体\n"
     ]
    }
   ],
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import os\n",
    "\n",
    "# 检查系统是否安装了 Arial 字体\n",
    "def is_arial_available():\n",
    "    for font in fm.fontManager.ttflist:\n",
    "        if 'Arial' in font.name:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# 如果系统没有 Arial 字体，加载用户自定义字体\n",
    "if not is_arial_available():\n",
    "    user_font_path = os.path.expanduser('~/.local/share/fonts/ARIAL.TTF')\n",
    "    if os.path.exists(user_font_path):\n",
    "        # 添加用户字体到 Matplotlib 的字体管理器\n",
    "        fm.fontManager.addfont(user_font_path)\n",
    "        # 设置 Matplotlib 使用该字体\n",
    "        plt.rcParams['font.family'] = 'sans-serif'\n",
    "        plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans', 'Liberation Sans']\n",
    "        print(\"已加载用户自定义 Arial 字体\")\n",
    "    else:\n",
    "        print(\"未找到用户自定义 Arial 字体文件\")\n",
    "else:\n",
    "    print(\"系统已安装 Arial 字体\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ihs_transform(data):\n",
    "    \"\"\"\n",
    "    使用反双曲正弦变换（IHS）对数据进行对数化处理，可以直接处理负值和零值\n",
    "    \n",
    "    参数:\n",
    "    data: ndarray, 输入数据，假设每一列是一个特征\n",
    "    \n",
    "    返回:\n",
    "    ihs_data: ndarray, IHS变换后的数据\n",
    "    \"\"\"\n",
    "    ihs_data = np.log(data + np.sqrt(data**2 + 1))\n",
    "    return ihs_data\n",
    "\n",
    "def inverse_ihs_transform(ihs_data):\n",
    "    \"\"\"\n",
    "    反双曲正弦变换（IHS）的逆变换，将数据还原为原始值\n",
    "    \n",
    "    参数:\n",
    "    ihs_data: ndarray, IHS变换后的数据\n",
    "    \n",
    "    返回:\n",
    "    data: ndarray, 还原后的数据\n",
    "    \"\"\"\n",
    "    data = np.sinh(ihs_data)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置数据类型\n",
    "DTYPE = torch.float32\n",
    "# 设置随机种子\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "df = {}\n",
    "# 读取数据\n",
    "url = '../data/sx_real_data.xlsx'\n",
    "df = pd.read_excel(url, sheet_name=None)\n",
    "data_HF = [[k, v] for k, v in df.items()]  # k is the sheet name, v is the pandas df\n",
    "# 循环遍历 data_HF 列表并获取下标\n",
    "data_train=pd.DataFrame()\n",
    "data_valid=pd.DataFrame()\n",
    "data_special=pd.DataFrame()\n",
    "for i, (sheet_name, sheet_data) in enumerate(data_HF):\n",
    "    # #去除 sheet_data 中的零值\n",
    "    # sheet_data = sheet_data[(sheet_data != 0).all(axis=1)]\n",
    "    if i==25:\n",
    "        data_valid=sheet_data\n",
    "    if i<=17:\n",
    "        data_train=pd.concat([data_train, sheet_data], ignore_index=True)\n",
    "\n",
    "df_hf = pd.concat([data_train, data_valid], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据形状: X=(9234, 6), y=(9234, 1)\n",
      "验证数据形状: X=(513, 6), y=(513, 1)\n"
     ]
    }
   ],
   "source": [
    "# 创建MinMaxScaler对象\n",
    "X_scaler_gamma = MinMaxScaler()\n",
    "X_scaler_gammadot = MinMaxScaler()\n",
    "X_scaler_gamma_0 = MinMaxScaler()\n",
    "X_scaler_time = MinMaxScaler()\n",
    "X_scaler_delta_t = MinMaxScaler()\n",
    "X_scaler_gammadot_derivative = MinMaxScaler()  # gammadot对时间的导数的scaler\n",
    "X_scaler_gammadot_second_derivative = MinMaxScaler()  # 新增gammadot对时间的二阶导数的scaler\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "# 从训练数据提取特征和标签\n",
    "X_train_gamma = data_train[['gamma']].values\n",
    "X_train_gammadot = data_train[['gammadot']].values\n",
    "X_train_gamma_0 = data_train[['gamma_0']].values/100\n",
    "X_train_time = data_train[['Time']].values\n",
    "X_train_delta_t = data_train[['delta_t']].values\n",
    "y_train_raw = data_train[['sigma']].values\n",
    "\n",
    "# 计算gammadot对时间的一阶导数\n",
    "X_train_gammadot_derivative = np.gradient(X_train_gammadot.flatten(), X_train_time.flatten()).reshape(-1, 1)\n",
    "# 计算gammadot对时间的二阶导数\n",
    "X_train_gammadot_second_derivative = np.gradient(X_train_gammadot_derivative.flatten(), X_train_time.flatten()).reshape(-1, 1)\n",
    "\n",
    "# 对训练数据进行对数变换\n",
    "X_train_gamma_log = ihs_transform(X_train_gamma)\n",
    "X_train_gammadot_log = ihs_transform(X_train_gammadot)\n",
    "X_train_gamma_0_log = ihs_transform(X_train_gamma_0)\n",
    "X_train_time_log = ihs_transform(X_train_time)\n",
    "X_train_delta_t_log = ihs_transform(X_train_delta_t)\n",
    "X_train_gammadot_derivative_log = ihs_transform(X_train_gammadot_derivative)\n",
    "X_train_gammadot_second_derivative_log = ihs_transform(X_train_gammadot_second_derivative)\n",
    "y_train_raw_log = ihs_transform(y_train_raw)\n",
    "\n",
    "# 对训练数据进行归一化并保存归一化参数\n",
    "X_train_gamma_norm = X_scaler_gamma.fit_transform(X_train_gamma_log)\n",
    "X_train_gammadot_norm = X_scaler_gammadot.fit_transform(X_train_gammadot_log)\n",
    "X_train_gamma_0_norm = X_scaler_gamma_0.fit_transform(X_train_gamma_0_log)\n",
    "X_train_time_norm = X_scaler_time.fit_transform(X_train_time_log)\n",
    "X_train_delta_t_norm = X_scaler_delta_t.fit_transform(X_train_delta_t_log)\n",
    "X_train_gammadot_derivative_norm = X_scaler_gammadot_derivative.fit_transform(X_train_gammadot_derivative_log)\n",
    "X_train_gammadot_second_derivative_norm = X_scaler_gammadot_second_derivative.fit_transform(X_train_gammadot_second_derivative_log)\n",
    "y_train_normalized = y_scaler.fit_transform(y_train_raw_log)\n",
    "\n",
    "# 从验证数据提取特征和标签\n",
    "X_valid_gamma = data_valid[['gamma']].values\n",
    "X_valid_gammadot = data_valid[['gammadot']].values\n",
    "X_valid_gamma_0 = data_valid[['gamma_0']].values/100\n",
    "X_valid_time = data_valid[['Time']].values\n",
    "X_valid_delta_t = data_valid[['delta_t']].values\n",
    "y_valid_raw = data_valid[['sigma']].values\n",
    "\n",
    "# 计算验证集gammadot对时间的一阶导数\n",
    "X_valid_gammadot_derivative = np.gradient(X_valid_gammadot.flatten(), X_valid_time.flatten()).reshape(-1, 1)\n",
    "# 计算验证集gammadot对时间的二阶导数\n",
    "X_valid_gammadot_second_derivative = np.gradient(X_valid_gammadot_derivative.flatten(), X_valid_time.flatten()).reshape(-1, 1)\n",
    "\n",
    "# 验证数据进行对数变换\n",
    "X_valid_gamma_log = ihs_transform(X_valid_gamma)\n",
    "X_valid_gammadot_log = ihs_transform(X_valid_gammadot)\n",
    "X_valid_gamma_0_log = ihs_transform(X_valid_gamma_0)\n",
    "X_valid_time_log = ihs_transform(X_valid_time)\n",
    "X_valid_delta_t_log = ihs_transform(X_valid_delta_t)\n",
    "X_valid_gammadot_derivative_log = ihs_transform(X_valid_gammadot_derivative)\n",
    "X_valid_gammadot_second_derivative_log = ihs_transform(X_valid_gammadot_second_derivative)\n",
    "y_valid_raw_log = ihs_transform(y_valid_raw)\n",
    "\n",
    "\n",
    "# 使用训练数据的归一化参数对验证数据进行归一化\n",
    "X_valid_gamma_norm = X_scaler_gamma.transform(X_valid_gamma_log)\n",
    "X_valid_gammadot_norm = X_scaler_gammadot.transform(X_valid_gammadot_log)\n",
    "X_valid_gamma_0_norm = X_scaler_gamma_0.transform(X_valid_gamma_0_log)\n",
    "X_valid_time_norm = X_scaler_time.transform(X_valid_time_log)\n",
    "X_valid_delta_t_norm = X_scaler_delta_t.transform(X_valid_delta_t_log)\n",
    "X_valid_gammadot_derivative_norm = X_scaler_gammadot_derivative.transform(X_valid_gammadot_derivative_log)\n",
    "X_valid_gammadot_second_derivative_norm = X_scaler_gammadot_second_derivative.transform(X_valid_gammadot_second_derivative_log)\n",
    "y_valid_normalized = y_scaler.transform(y_valid_raw_log)\n",
    "\n",
    "# 合并归一化后的特征，加入time和gammadot的二阶导数\n",
    "X_train_normalized = np.hstack((X_train_gamma_norm, X_train_gammadot_norm,X_train_delta_t_norm, X_train_gamma_0_norm, X_train_gammadot_derivative_norm, X_train_gammadot_second_derivative_norm))\n",
    "X_valid_normalized = np.hstack((X_valid_gamma_norm, X_valid_gammadot_norm, X_valid_delta_t_norm, X_valid_gamma_0_norm, X_valid_gammadot_derivative_norm, X_valid_gammadot_second_derivative_norm))\n",
    "\n",
    "print(f\"训练数据形状: X={X_train_normalized.shape}, y={y_train_normalized.shape}\")\n",
    "print(f\"验证数据形状: X={X_valid_normalized.shape}, y={y_valid_normalized.shape}\")\n",
    "\n",
    "# 将归一化后的训练数据转换为tensor\n",
    "X_data_HF = torch.tensor(X_train_normalized, dtype=torch.float32)\n",
    "y_data_HF = torch.tensor(y_train_normalized, dtype=torch.float32)\n",
    "\n",
    "# 将归一化后的验证数据转换为tensor\n",
    "X_data_valid = torch.tensor(X_valid_normalized, dtype=torch.float32)\n",
    "y_data_valid = torch.tensor(y_valid_normalized, dtype=torch.float32)\n",
    "\n",
    "# 保存归一化参数\n",
    "# 将scaler存入元组\n",
    "scalers = (\n",
    "    X_scaler_gamma,\n",
    "    X_scaler_gammadot,\n",
    "    X_scaler_gamma_0,\n",
    "    X_scaler_time,\n",
    "    X_scaler_delta_t,\n",
    "    X_scaler_gammadot_derivative,\n",
    "    X_scaler_gammadot_second_derivative,\n",
    "    y_scaler\n",
    ")\n",
    "\n",
    "# 定义模型\n",
    "in_dim, out_dim = 6, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8712, 30, 6])\n",
      "torch.Size([8712, 1])\n"
     ]
    }
   ],
   "source": [
    "# 定义时间步长\n",
    "time_steps = 30\n",
    "\n",
    "# 动态窗口实现\n",
    "def create_dynamic_window(data, time_steps):\n",
    "    \"\"\"\n",
    "    通过动态窗口将数据调整为适合 LSTM 输入的格式。\n",
    "    :param data: 输入数据，形状为 (num_samples, ...)\n",
    "    :param time_steps: 时间步长\n",
    "    :return: 调整后的数据，形状为 (num_samples - time_steps + 1, time_steps, ...)\n",
    "    \"\"\"\n",
    "    num_samples = data.shape[0]\n",
    "    if num_samples < time_steps:\n",
    "        raise ValueError(\"样本数量必须大于等于时间步长\")\n",
    "    \n",
    "    # 创建动态窗口\n",
    "    windowed_data = []\n",
    "    for i in range(num_samples - time_steps + 1):\n",
    "        window = data[i:i + time_steps]\n",
    "        windowed_data.append(window)\n",
    "    \n",
    "    return torch.stack(windowed_data)\n",
    "\n",
    "# 调整 X_data_HF 和 y_data_HF\n",
    "# 根据 gamma_0 的值对 X_data_HF 进行分组\n",
    "unique_gamma_0 = torch.unique(X_data_HF[:, 3])  # 假设 gamma_0 在第三列\n",
    "grouped_X_data = []\n",
    "grouped_y_data = []\n",
    "\n",
    "for gamma_0_value in unique_gamma_0:\n",
    "    # 选择当前 gamma_0 值对应的数据\n",
    "    group_mask = X_data_HF[:, 3] == gamma_0_value\n",
    "    group_X_data = X_data_HF[group_mask]\n",
    "    group_y_data = y_data_HF[group_mask]\n",
    "    \n",
    "    # 对当前组数据应用动态窗口\n",
    "    windowed_group_X_data = create_dynamic_window(group_X_data, time_steps)\n",
    "    windowed_group_y_data = create_dynamic_window(group_y_data, time_steps)\n",
    "    \n",
    "    # 通常是目标值，只需要取每个窗口的最后一个时间步的值\n",
    "    windowed_group_y_data = windowed_group_y_data[:, -1, :]\n",
    "    \n",
    "    grouped_X_data.append(windowed_group_X_data)\n",
    "    grouped_y_data.append(windowed_group_y_data)\n",
    "\n",
    "# 将所有组的数据拼接起来\n",
    "X_data_HF = torch.cat(grouped_X_data, dim=0)\n",
    "y_data_HF = torch.cat(grouped_y_data, dim=0)\n",
    "\n",
    "print(X_data_HF.shape)\n",
    "print(y_data_HF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调整 X_data_valid\n",
    "X_data_valid = create_dynamic_window(X_data_valid, time_steps)\n",
    "# 调整 y_data_HF\n",
    "# 注意：y_data_HF 通常是目标值，只需要取最后一个时间步的值\n",
    "y_data_valid = y_data_valid[time_steps-1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_NeuralNet(nn.Module):\n",
    "    \"\"\" Set basic architecture of the PINN model using GRU.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim=0,\n",
    "                 output_dim=1,  # 默认输出维度为1\n",
    "                 hidden_size=20,  # GRU 隐藏层的维度\n",
    "                 num_layers=4,    # GRU 层数\n",
    "                 activation='tanh',\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 **kwargs):\n",
    "        super(GRU_NeuralNet, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # 添加 GRU 层\n",
    "        self.gru = nn.GRU(input_dim, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # 添加第一层全连接层（从 GRU 的隐藏状态映射到中间层）\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size)  # 中间层的维度可以与 hidden_size 相同\n",
    "        \n",
    "        # 添加第二层全连接层（从中间层映射到输出维度）\n",
    "        self.out = nn.Linear(hidden_size, output_dim)\n",
    "        \n",
    "        # 设置激活函数\n",
    "        if activation == 'tanh':\n",
    "            self.activation = torch.tanh\n",
    "        elif activation == 'relu':\n",
    "            self.activation = F.relu6\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = torch.sigmoid\n",
    "        elif activation == 'linear':\n",
    "            self.activation = None\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "        \n",
    "        # 初始化权重\n",
    "        if kernel_initializer == 'glorot_normal':\n",
    "            for name, param in self.gru.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_normal_(param)\n",
    "            nn.init.xavier_normal_(self.fc1.weight)\n",
    "            nn.init.xavier_normal_(self.out.weight)\n",
    "        elif kernel_initializer == 'glorot_uniform':\n",
    "            for name, param in self.gru.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "            nn.init.xavier_uniform_(self.fc1.weight)\n",
    "            nn.init.xavier_uniform_(self.out.weight)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported kernel initializer\")\n",
    "\n",
    "    def forward(self, X):\n",
    "        # GRU 输入形状: (batch_size, seq_len, input_dim)\n",
    "        # GRU 输出形状: (batch_size, seq_len, hidden_size)\n",
    "        # 初始化隐藏状态\n",
    "        h0 = torch.zeros(self.num_layers, X.size(0), self.hidden_size).to(X.device)\n",
    "        \n",
    "        # 通过 GRU 层\n",
    "        gru_out, _ = self.gru(X, h0)\n",
    "        \n",
    "        # 取最后一个时间步的输出\n",
    "        last_time_step = gru_out[:, -1, :]  # (batch_size, hidden_size)\n",
    "        \n",
    "        # 通过第一层全连接层\n",
    "        Z = self.fc1(last_time_step)\n",
    "        \n",
    "        # 应用激活函数（如果需要）\n",
    "        if self.activation is not None:\n",
    "            Z = self.activation(Z)\n",
    "        \n",
    "        # 通过第二层全连接层\n",
    "        Z = self.out(Z)\n",
    "        \n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_NeuralNet(nn.Module):\n",
    "    \"\"\" 设置基本的MLP模型架构。\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim=0,\n",
    "                 output_dim=1,  # 默认输出维度为1\n",
    "                 hidden_size=20,  # 隐藏层的维度\n",
    "                 num_layers=4,    # 隐藏层数\n",
    "                 activation='tanh',\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 **kwargs):\n",
    "        super(MLP_NeuralNet, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # 创建层列表\n",
    "        layers = []\n",
    "        \n",
    "        # 输入层到第一个隐藏层\n",
    "        layers.append(nn.Linear(input_dim, hidden_size))\n",
    "        \n",
    "        # 添加激活函数\n",
    "        if activation == 'tanh':\n",
    "            act_func = nn.Tanh()\n",
    "        elif activation == 'relu':\n",
    "            act_func = nn.ReLU6()\n",
    "        elif activation == 'sigmoid':\n",
    "            act_func = nn.Sigmoid()\n",
    "        elif activation == 'linear':\n",
    "            act_func = None\n",
    "        else:\n",
    "            raise ValueError(\"不支持的激活函数\")\n",
    "        \n",
    "        self.activation = act_func\n",
    "        \n",
    "        # 添加中间隐藏层\n",
    "        for _ in range(num_layers - 1):\n",
    "            if self.activation is not None:\n",
    "                layers.append(self.activation)\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        # 添加最后一层（输出层）\n",
    "        if self.activation is not None:\n",
    "            layers.append(self.activation)\n",
    "        layers.append(nn.Linear(hidden_size, output_dim))\n",
    "        \n",
    "        # 创建顺序模型\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "        # 初始化权重\n",
    "        if kernel_initializer == 'glorot_normal':\n",
    "            for layer in self.model:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_normal_(layer.weight)\n",
    "        elif kernel_initializer == 'glorot_uniform':\n",
    "            for layer in self.model:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "        else:\n",
    "            raise ValueError(\"不支持的权重初始化方法\")\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 只使用序列中的最后一个时间步的数据\n",
    "        X_last = X[:, -1, :]  # 提取每个序列的最后一个时间步\n",
    "        \n",
    "        # 通过MLP模型处理最后一个时间步的数据\n",
    "        Z = self.model(X_last)\n",
    "        \n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络处理器类\n",
    "class PINNSolver():\n",
    "\n",
    "    # 类属性定义\n",
    "    def __init__(self, model):\n",
    "        self.model = model # \n",
    "        # Initialize history of losses and global iteration counter\n",
    "        self.hist =  [[], []] # loss历史列表,0:train loss ;1:valid loss\n",
    "        self.iter = 0 # 迭代次数\n",
    "        self.last_n_losses = [] # 前损失列表\n",
    "        # 初始化G和eta为可学习参数\n",
    "        self.G = torch.tensor(0.1, requires_grad=True)\n",
    "        self.eta = torch.tensor(0.1, requires_grad=True)\n",
    "\n",
    "    # 更新损失列表   \n",
    "    def update_last_n_losses(self, loss):\n",
    "        self.last_n_losses.append(loss)\n",
    "        if len(self.last_n_losses) > 20:\n",
    "            self.last_n_losses.pop(0)\n",
    "\n",
    "    # 计算最大相对误差        \n",
    "    def ES(self):\n",
    "        if len(self.last_n_losses) < 20:\n",
    "            return 100  # a large number\n",
    "\n",
    "        current_loss = self.last_n_losses[-1]\n",
    "        max_relative_error = 100.*max([abs(current_loss - loss) / current_loss for loss in self.last_n_losses[:-1]])\n",
    "        return max_relative_error\n",
    "    \n",
    "    # 使用最小二乘法拟合G和eta\n",
    "    def fit_G_eta(self, X_batch, y_batch):\n",
    "        # 提取物理量\n",
    "        strain = X_batch[:, :, 0]  # 应变\n",
    "        strain_rate = X_batch[:, :, 1]  # 应变率\n",
    "        time_steps = X_batch[:, :, 2]  # 时间步\n",
    "        stress = y_batch  # 实际应力\n",
    "        \n",
    "        # 确保数据维度足够\n",
    "        if X_batch.shape[1] <= 1 or stress.shape[1] <= 1:\n",
    "            return  # 如果数据不足，直接返回\n",
    "            \n",
    "        # 计算时间步差\n",
    "        dt = time_steps[:, 1:] - time_steps[:, :-1]\n",
    "        \n",
    "        # 计算应力变化率\n",
    "        stress_rate = (stress[:, 1:] - stress[:, :-1]) / dt\n",
    "        \n",
    "        # 检查张量维度是否匹配\n",
    "        if strain_rate[:, :-1].shape != stress[:, :-1].shape:\n",
    "            # 如果维度不匹配，跳过拟合\n",
    "            return\n",
    "            \n",
    "        # 准备最小二乘法拟合的数据\n",
    "        # Maxwell方程: stress_rate + (G/η)*stress = G*strain_rate\n",
    "        # 重写为: stress_rate = G*strain_rate - (G/η)*stress\n",
    "        \n",
    "        # 构建线性系统 Ax = b\n",
    "        # A的第一列是strain_rate，第二列是-stress\n",
    "        try:\n",
    "            A = torch.stack([\n",
    "                strain_rate[:, :-1].flatten(),\n",
    "                -stress[:, :-1].flatten()\n",
    "            ], dim=1)\n",
    "            \n",
    "            # b是stress_rate\n",
    "            b = stress_rate.flatten()\n",
    "            \n",
    "            # 使用最小二乘法求解\n",
    "            # 解决方案: x = (A^T A)^(-1) A^T b\n",
    "            # x[0] = G, x[1] = G/η\n",
    "            \n",
    "            # 计算A^T A\n",
    "            ATA = torch.matmul(A.t(), A)\n",
    "            # 计算A^T b\n",
    "            ATb = torch.matmul(A.t(), b)\n",
    "            \n",
    "            # 求解线性系统\n",
    "            try:\n",
    "                x = torch.linalg.solve(ATA, ATb)\n",
    "                # 提取G和eta\n",
    "                G_fit = x[0]\n",
    "                G_over_eta = x[1]\n",
    "                eta_fit = G_fit / G_over_eta if G_over_eta != 0 else torch.tensor(10.0)\n",
    "                \n",
    "                # 更新G和eta\n",
    "                self.G = G_fit\n",
    "                self.eta = eta_fit\n",
    "            except:\n",
    "                # 如果求解失败，保持当前值\n",
    "                print(f\"拟合G和eta时出错: {e}\")\n",
    "                pass\n",
    "        except RuntimeError as e:\n",
    "            # 捕获维度不匹配的错误\n",
    "            print(f\"拟合G和eta时出错: {e}\")\n",
    "            print(f\"strain_rate形状: {strain_rate.shape}, stress形状: {stress.shape}\")\n",
    "            # 保持当前值\n",
    "            pass\n",
    "    \n",
    "    # 计算loss，模型核心\n",
    "    def loss_fn(self, X_data_HF, y_data_HF, X_data_valid, y_data_valid):\n",
    "        # 首先使用最小二乘法拟合G和eta\n",
    "        try:\n",
    "            self.fit_G_eta(X_data_HF, y_data_HF)\n",
    "        except Exception as e:\n",
    "            print(f\"拟合G和eta时发生异常: {e}\")\n",
    "        \n",
    "        y_pred_valid = self.model(X_data_valid)    \n",
    "        y_pred_HF = self.model(X_data_HF)\n",
    "\n",
    "        # L2正则化损失\n",
    "        Loss_L2 = 1e-5 * sum(torch.sum(w_**2) for w_ in self.model.parameters())\n",
    "        \n",
    "        # 计算高频数据集的 Huber Loss\n",
    "        Loss_data_HF = F.smooth_l1_loss(y_pred_HF, y_data_HF) + Loss_L2\n",
    "        Loss_data_valid = F.smooth_l1_loss(y_pred_valid, y_data_valid) + Loss_L2\n",
    "        \n",
    "        # 添加Maxwell物理损失\n",
    "        # 提取相关物理量\n",
    "        strain = X_data_HF[:, :, 0]  # 应变\n",
    "        strain_rate = X_data_HF[:, :, 1]  # 应变率\n",
    "        stress_pred = y_pred_HF  # 预测的应力\n",
    "        \n",
    "        # 检查张量维度，确保不为空\n",
    "        if X_data_HF.shape[1] > 1 and stress_pred.shape[1] > 0:\n",
    "            try:\n",
    "                # 计算Maxwell模型的物理约束\n",
    "                # Maxwell模型: 应力率 + (G/η)应力 = G*应变率\n",
    "                \n",
    "                # 计算应力的时间导数（简化为差分）\n",
    "                # 从输入数据中获取时间步\n",
    "                dt = X_data_HF[:, 1:, 2] - X_data_HF[:, :-1, 2]  # 使用X的第三列作为时间\n",
    "                \n",
    "                # 确保stress_pred的维度与dt匹配\n",
    "                if stress_pred.shape[1] > 1:\n",
    "                    # 计算应力随时间的变化率\n",
    "                    stress_rate = (stress_pred[:, 1:] - stress_pred[:, :-1]) / dt\n",
    "                    \n",
    "                    # Maxwell方程约束，使用拟合的参数G和eta\n",
    "                    maxwell_residual = stress_rate + (self.G/self.eta)*stress_pred[:, :-1] - self.G*strain_rate[:, :-1]\n",
    "                    Loss_physics = torch.mean(maxwell_residual**2)  # 物理损失权重可调\n",
    "                    \n",
    "                    # 合并所有损失\n",
    "                    Loss_data_HF = Loss_data_HF + Loss_physics\n",
    "            except Exception as e:\n",
    "                print(f\"计算物理损失时发生异常: {e}\")\n",
    "        \n",
    "        return Loss_data_HF, Loss_data_valid\n",
    "    \n",
    "    # 训练核心函数，包括loss计算梯度计算和反向传播\n",
    "    def solve_with_PyTorch_optimizer(self, optimizer, data, scheduler, batch_size, N=1001):\n",
    "        \"\"\"This method performs a gradient descent type optimization.\"\"\"\n",
    "        # 解包数据\n",
    "        X_data_HF, y_data_HF, X_data_valid, y_data_valid = data\n",
    "\n",
    "        # 创建训练数据集和 DataLoader\n",
    "        train_dataset = TensorDataset(X_data_HF, y_data_HF)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "        for i in range(N):\n",
    "            # 初始化 epoch 的总损失\n",
    "            epoch_loss_sum = 0.0\n",
    "            num_batches = 0\n",
    "            # 遍历每个批次\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                # 确保批次数据不为空且维度正确\n",
    "                if X_batch.shape[0] == 0 or X_batch.shape[1] <= 1 or y_batch.shape[1] <= 0:\n",
    "                    continue  # 跳过空批次或维度不足的批次\n",
    "                \n",
    "                # 梯度清0\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                try:\n",
    "                    # 计算 loss\n",
    "                    loss, _ = self.loss_fn(X_batch, y_batch, X_data_valid, y_data_valid)\n",
    "\n",
    "                    # 反向传播计算梯度\n",
    "                    loss.backward()\n",
    "\n",
    "                    # 反向传播更新权重和偏置\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # 累加每个批次的损失\n",
    "                    epoch_loss_sum += loss.item()\n",
    "                    num_batches += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"批次训练时发生异常: {e}\")\n",
    "                    print(f\"X_batch形状: {X_batch.shape}, y_batch形状: {y_batch.shape}\")\n",
    "                    continue\n",
    "\n",
    "            # 计算 epoch 的平均损失\n",
    "            # 在整个验证集上计算验证损失\n",
    "            try:\n",
    "                loss_train, loss_valid = self.loss_fn(X_data_HF, y_data_HF, X_data_valid, y_data_valid)\n",
    "\n",
    "                # 记录 epoch 的平均损失\n",
    "                self.current_loss = loss_train.item()\n",
    "                self.valid_loss = loss_valid.item()\n",
    "                # 根据 epoch 的平均损失调度学习率\n",
    "                scheduler.step(loss_train)\n",
    "                \n",
    "                # 计算相对误差\n",
    "                self.max_relative_error = self.ES()\n",
    "                self.callback(self.max_relative_error, N)  # 将 max_relative_error 传递给回调函数\n",
    "                self.update_last_n_losses(self.current_loss)\n",
    "\n",
    "                # 早停机制\n",
    "                if self.max_relative_error < 2e-3:  # 以 % 为单位\n",
    "                    print('Early stopping... \\nIt {:05,d}: Loss = {:10.4e}, Max. rel. error = {} %'.format(self.iter,\n",
    "                                                                                                        self.current_loss,\n",
    "                                                                                                        np.round(self.max_relative_error, 3)))\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"计算epoch损失时发生异常: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # 打印loss    \n",
    "    def callback(self, xr=None,N=1001):\n",
    "        if self.iter % 100 == 0:\n",
    "            print('It {:05,d}: Loss = {:10.4e}, Valid Loss = {:10.4e}, Max. rel. error = {} %, G = {:.4f}, eta = {:.4f}'.format(\n",
    "                self.iter,\n",
    "                self.current_loss,\n",
    "                self.valid_loss,\n",
    "                np.round(self.max_relative_error, 2),\n",
    "                self.G.item(),\n",
    "                self.eta.item()))\n",
    "        self.hist[0].append(self.current_loss)\n",
    "        self.hist[1].append(self.valid_loss)\n",
    "        self.iter+=1\n",
    "    \n",
    "    def plot_loss_history(self, ax=None):\n",
    "        if not ax:\n",
    "            fig = plt.figure(figsize=(8, 6),dpi=600)\n",
    "            ax = fig.add_subplot(111)\n",
    "\n",
    "        # 绘制训练集损失曲线\n",
    "        ax.semilogy(range(len(self.hist[0])), self.hist[0], 'b-', label='Training Loss')\n",
    "        \n",
    "        # 绘制验证集损失曲线\n",
    "        ax.semilogy(range(len(self.hist[1])), self.hist[1], 'g-', label='Validation Loss')\n",
    "\n",
    "        ax.set_xlabel('$n_{epoch}$')\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, pos: f'{int(x):,}'))\n",
    "        ax.legend()  # 添加图例\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= GRU_NeuralNet(input_dim=in_dim,\n",
    "                             output_dim=out_dim,\n",
    "                             num_layers=4,\n",
    "                             hidden_size=20,\n",
    "                             activation='relu')\n",
    "\n",
    "# model=MLP_NeuralNet(input_dim=in_dim,\n",
    "#                     output_dim=out_dim,\n",
    "#                     hidden_size=30,\n",
    "#                     num_layers=4,\n",
    "#                     activation='relu')\n",
    "# 初始化 PINNSolver\n",
    "solver = PINNSolver(model)\n",
    "model = model.to(device)  # 将模型移动到 GPU\n",
    "X_data_HF,y_data_HF,X_data_valid,y_data_valid\n",
    "# 假设 X_data_HF, y_data_HF, X_data_valid, y_data_valid 是 PyTorch 张量\n",
    "X_data_HF = X_data_HF.to(device)  # 将训练集输入数据移动到 GPU\n",
    "y_data_HF = y_data_HF.to(device)  # 将训练集标签数据移动到 GPU\n",
    "\n",
    "X_data_valid = X_data_valid.to(device)  # 将验证集输入数据移动到 GPU\n",
    "y_data_valid = y_data_valid.to(device)  # 将验证集标签数据移动到 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/redfu/anaconda3/envs/PINN/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:240: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It 0,000: Loss = 5.2387e-02, Valid Loss = 1.6439e-01, Max. rel. error = 100 %, G = 0.1000, eta = 0.1000\n",
      "It 0,100: Loss = 2.2194e-02, Valid Loss = 7.3985e-02, Max. rel. error = 202.53 %, G = 0.1000, eta = 0.1000\n",
      "It 0,200: Loss = 1.6865e-02, Valid Loss = 6.7836e-02, Max. rel. error = 85.05 %, G = 0.1000, eta = 0.1000\n",
      "It 0,300: Loss = 8.2417e-03, Valid Loss = 6.8742e-02, Max. rel. error = 74.12 %, G = 0.1000, eta = 0.1000\n",
      "\n",
      "Runtime: 6.184 minutes\n"
     ]
    }
   ],
   "source": [
    "# 定义学习率调度器\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(list(model.parameters()), lr=lr)\n",
    "# 使用MultiStepLR来在指定epoch改变学习率\n",
    "# 在第1000个epoch时将学习率乘以0.1\n",
    "milestones = [500]  # 在这里可以添加多个节点，例如[500, 1000, 1500]\n",
    "gamma = 0.1  # 学习率衰减因子\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
    "batch=484\n",
    "# 定义训练模式\n",
    "mode = 'PyTorch_optimizer'\n",
    "N = int(2000) + 1  # 训练迭代次数\n",
    "\n",
    "try:\n",
    "    runtime\n",
    "except NameError:\n",
    "    runtime = 0.\n",
    "\n",
    "if mode == 'PyTorch_optimizer':\n",
    "    try:\n",
    "        t0 = time()\n",
    "        solver.solve_with_PyTorch_optimizer(optimizer, [X_data_HF,y_data_HF,X_data_valid,y_data_valid],scheduler,batch,N=N)\n",
    "        runtime += (time() - t0) / 60.\n",
    "        print('\\nRuntime: {:.3f} minutes'.format(runtime))\n",
    "    except KeyboardInterrupt:\n",
    "        runtime += (time() - t0) / 60.\n",
    "        print('\\nRuntime: {:.3f} minutes'.format(runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.plot_loss_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一设置字体为 Arial 24 pt\n",
    "plt.rcParams['font.family'] = 'Arial'  # 设置字体为 Arial\n",
    "plt.rcParams['font.size'] = 24 # 三拼图为36，单图为12最佳\n",
    "model.eval()\n",
    "# 颜色字典\n",
    "colors = {\n",
    "    'red': 'tab:red',\n",
    "    'orange': 'tab:orange', \n",
    "    'yellow': '#f9c74f',\n",
    "    'green': 'tab:green',\n",
    "    'cyan': 'tab:cyan',\n",
    "    'blue': 'tab:blue',\n",
    "    'purple': 'tab:purple',\n",
    "    'brown': 'tab:brown',\n",
    "    'pink': 'tab:pink',\n",
    "    'black': '#000000'\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=600)\n",
    "\n",
    "# 训练集预测\n",
    "y_train_pred = model(X_data_HF)\n",
    "y_train_pred = y_train_pred.cpu().detach().numpy()\n",
    "y_train_pred_denorm = y_scaler.inverse_transform(y_train_pred)\n",
    "y_train_pred_denorm = inverse_ihs_transform(y_train_pred_denorm)\n",
    "# 验证集预测  \n",
    "y_valid_pred = model(X_data_valid)\n",
    "y_valid_pred = y_valid_pred.cpu().detach().numpy()\n",
    "y_valid_pred_denorm = y_scaler.inverse_transform(y_valid_pred)\n",
    "y_valid_pred_denorm = inverse_ihs_transform(y_valid_pred_denorm)\n",
    "\n",
    "\n",
    "# 绘制验证集\n",
    "ax.plot(X_valid_gamma[time_steps-1:], y_valid_pred_denorm[:,0], color=colors['red'], label='Prediction')\n",
    "ax.scatter(X_valid_gamma[time_steps-1:], y_valid_raw[time_steps-1:,0], color=colors['black'], marker='o', s=12, label='Real')\n",
    "# 创建新的图形和坐标轴\n",
    "\n",
    "ax.set_ylabel('$\\sigma_{12}$ (Pa)')\n",
    "ax.set_xlabel('$\\gamma_{12}$')\n",
    "\n",
    "# 调整图例\n",
    "legend = ax.legend(fontsize=18, loc='best')\n",
    "plt.show()\n",
    "# 创建新的图形和坐标轴用于绘制验证集残差图\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=600)\n",
    "\n",
    "# 计算残差（真实值 - 预测值）\n",
    "residuals = y_valid_raw[time_steps-1:, 0] - y_valid_pred_denorm[:, 0]\n",
    "\n",
    "# 绘制残差图\n",
    "ax.scatter(X_valid_time[time_steps-1:], residuals, color=colors['blue'], marker='o', s=12)\n",
    "ax.axhline(y=0, color='black', linestyle='--', alpha=0.7)  # 添加y=0的水平参考线\n",
    "\n",
    "# 设置标签和标题\n",
    "ax.set_xlabel('$Time (s)$')\n",
    "ax.set_ylabel('Radisual (Pa)')\n",
    "\n",
    "# 添加网格线以提高可读性\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 定义评估指标计算函数\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算R2、MAE和MAPE评估指标\n",
    "    \n",
    "    参数:\n",
    "    y_true: 真实值\n",
    "    y_pred: 预测值\n",
    "    \n",
    "    返回:\n",
    "    包含R2、MAE和MAPE的字典\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import r2_score, mean_absolute_error\n",
    "    import numpy as np\n",
    "    \n",
    "    # 计算R2分数\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # 计算MAE (平均绝对误差)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # 计算MAPE (平均绝对百分比误差)\n",
    "    # 避免除以零\n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    \n",
    "    return {\n",
    "        'R2': r2,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "\n",
    "# 计算验证集的评估指标\n",
    "valid_metrics = calculate_metrics(\n",
    "    y_valid_raw[time_steps-1:, 0],  # 真实值\n",
    "    y_valid_pred_denorm[:, 0]       # 预测值\n",
    ")\n",
    "\n",
    "# 打印评估指标\n",
    "print(\"\\n验证集评估指标:\")\n",
    "print(f\"R2 分数: {valid_metrics['R2']:.4f}\")\n",
    "print(f\"MAE (平均绝对误差): {valid_metrics['MAE']:.4f}\")\n",
    "print(f\"MAPE (平均绝对百分比误差): {valid_metrics['MAPE']:.4f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, '../model/real/gru.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 接下来是论文绘图代码\n",
    "- 主要绘制不同本构模型的对比图\n",
    "- 预测值与真实值的对比图\n",
    "- 残差图\n",
    "- 评估指标柱状图 R2,MAE,MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统一设置字体为 Arial 24 pt\n",
    "plt.rcParams['font.family'] = 'Arial'  # 设置字体为 Arial\n",
    "plt.rcParams['font.size'] = 24 # \n",
    "model_maxwell=torch.load('../model/real/pigru-maxwell.pth')\n",
    "model_sls=torch.load('../model/real/pigru-sls.pth')\n",
    "model_fsls=torch.load('../model/real/pigru-fsls.pth')\n",
    "model_gru=torch.load('../model/real/gru.pth')  # 加载新的GRU模型\n",
    "# Nature风格配色\n",
    "colors = {\n",
    "    'blue': '#4878D0',    # 蓝色\n",
    "    'orange': '#EE854A',  # 橙色\n",
    "    'green': '#6ACC64',   # 绿色\n",
    "    'red': '#D65F5F',     # 红色\n",
    "    'purple': '#956CB4',  # 紫色\n",
    "    'brown': '#8C613C',   # 棕色\n",
    "    'pink': '#DC7EC0',    # 粉色\n",
    "    'gray': '#797979',    # 灰色\n",
    "    'yellow': '#D5BB67',  # 黄色\n",
    "    'cyan': '#82C6E2',    # 青色\n",
    "    'black': '#000000'    # 黑色\n",
    "}\n",
    "\n",
    "# 定义不同的标记符号\n",
    "markers = {\n",
    "    'maxwell': 's',      # 方形\n",
    "    'sls': '*',    # 星形，更改为与菱形差异更大的符号\n",
    "    'fsls': 'v',    # 倒三角形，更改为与星形差异更大的符号\n",
    "    'gru': 'D',     # 菱形，为新模型添加标记\n",
    "}\n",
    "\n",
    "# 定义评估指标计算函数\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算R2、MAE和MAPE评估指标\n",
    "    \n",
    "    参数:\n",
    "    y_true: 真实值\n",
    "    y_pred: 预测值\n",
    "    \n",
    "    返回:\n",
    "    包含R2、MAE和MAPE的字典\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import r2_score, mean_absolute_error\n",
    "    import numpy as np\n",
    "    \n",
    "    # 计算R2分数\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # 计算MAE (平均绝对误差)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    # 计算MAPE (平均绝对百分比误差)\n",
    "    # 避免除以零\n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    \n",
    "    return {\n",
    "        'R2': r2,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "\n",
    "# 创建函数用于生成预测结果和评估指标\n",
    "def generate_predictions_and_metrics(model, X_data, is_xgb=False):\n",
    "    \n",
    "    if is_xgb:\n",
    "        # XGBoost模型预测\n",
    "        dtest = xgb.DMatrix(X_data)\n",
    "        y_pred = model.predict(dtest)\n",
    "        y_pred = y_pred.reshape(-1, 1)\n",
    "            # 反归一化\n",
    "        y_pred_denorm = y_scaler.inverse_transform(y_pred)\n",
    "        y_pred_denorm = inverse_ihs_transform(y_pred_denorm)\n",
    "        metrics = calculate_metrics(\n",
    "                y_valid_raw[time_steps-1:, 0],  # 真实值\n",
    "                y_pred_denorm[time_steps-1:, 0]             # 预测值\n",
    "            )\n",
    "    else:\n",
    "        # PyTorch模型预测\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_data)\n",
    "            y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "        y_pred_denorm = y_scaler.inverse_transform(y_pred)\n",
    "        y_pred_denorm = inverse_ihs_transform(y_pred_denorm)\n",
    "        metrics = calculate_metrics(\n",
    "                y_valid_raw[time_steps-1:, 0],  # 真实值\n",
    "                y_pred_denorm[:, 0]             # 预测值\n",
    "            )\n",
    "    \n",
    "    # 计算评估指标\n",
    "    return y_pred_denorm, metrics\n",
    "\n",
    "# 生成各模型的预测结果和评估指标\n",
    "y_pred_maxwell, metrics_maxwell = generate_predictions_and_metrics(model_maxwell, X_data_valid)\n",
    "y_pred_sls, metrics_sls = generate_predictions_and_metrics(model_sls, X_data_valid)\n",
    "y_pred_fsls, metrics_fsls = generate_predictions_and_metrics(model_fsls, X_data_valid)\n",
    "y_pred_gru, metrics_gru = generate_predictions_and_metrics(model_gru, X_data_valid)  # 生成GRU模型的预测结果\n",
    "\n",
    "# 绘制预测值-真实值对比图（所有模型在一张图上）\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=600)\n",
    "\n",
    "# 绘制各模型预测结果，使用不同的标记符号\n",
    "ax.plot(X_valid_gamma[time_steps-1:], y_pred_gru[:, 0], color=colors['red'], marker=markers['gru'], markevery=10, markersize=7, label='DD')  # 添加GRU模型的预测结果\n",
    "ax.plot(X_valid_gamma[time_steps-1:], y_pred_maxwell[:, 0], color=colors['green'], marker=markers['maxwell'], markevery=10, markersize=5, label='M',markerfacecolor='none')\n",
    "ax.plot(X_valid_gamma[time_steps-1:], y_pred_sls[:, 0], color=colors['purple'], marker=markers['sls'], markevery=10, markersize=8, label='SLS')\n",
    "ax.plot(X_valid_gamma[time_steps-1:], y_pred_fsls[:, 0], color=colors['yellow'], marker=markers['fsls'], markevery=10, markersize=8, label='FSLS')\n",
    "\n",
    "ax.scatter(X_valid_gamma[time_steps-1:], y_valid_raw[time_steps-1:, 0], color=colors['black'], marker='o', s=15, label='Real')\n",
    "\n",
    "# 设置标签和标题\n",
    "ax.set_xlabel('$\\gamma_{12}$')\n",
    "ax.set_ylabel('$\\sigma_{12}$ (Pa)')\n",
    "ax.legend(fontsize=18, loc='upper left', frameon=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 绘制残差对比图（所有模型在一张图上）\n",
    "fig, ax = plt.subplots(figsize=(8, 6), dpi=600)\n",
    "\n",
    "# 计算各模型残差\n",
    "# residuals_xgb = y_valid_raw[time_steps-1:, 0] - y_pred_xgb[time_steps-1:, 0]\n",
    "residuals_maxwell = y_valid_raw[time_steps-1:, 0] - y_pred_maxwell[:, 0]\n",
    "residuals_sls = y_valid_raw[time_steps-1:, 0] - y_pred_sls[:, 0]\n",
    "residuals_fsls = y_valid_raw[time_steps-1:, 0] - y_pred_fsls[:, 0]\n",
    "residuals_gru = y_valid_raw[time_steps-1:, 0] - y_pred_gru[:, 0]  # 计算GRU模型的残差\n",
    "\n",
    "# 绘制各模型残差，使用不同的标记符号\n",
    "ax.scatter(X_valid_time[time_steps-1:], residuals_gru, color=colors['red'], marker=markers['gru'], s=20, label='DD',facecolor='none')  # 添加GRU模型的残差\n",
    "ax.scatter(X_valid_time[time_steps-1:], residuals_maxwell, color=colors['green'], marker=markers['maxwell'], s=20, label='M',facecolor='none')\n",
    "ax.scatter(X_valid_time[time_steps-1:], residuals_sls, color=colors['purple'], marker=markers['sls'], s=20, label='SLS',facecolor='none')\n",
    "ax.scatter(X_valid_time[time_steps-1:], residuals_fsls, color=colors['yellow'], marker=markers['fsls'], s=20, label='FSLS',facecolor='none')\n",
    "\n",
    "ax.axhline(y=0, color=colors['black'], linestyle='--', linewidth=2)\n",
    "\n",
    "# 设置标签和标题\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Residual (Pa)')\n",
    "ax.legend(fontsize=18, loc='best', frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(metrics_gru)  # 打印GRU模型的评估指标\n",
    "print(metrics_maxwell)\n",
    "print(metrics_sls)\n",
    "print(metrics_fsls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 绘制指标柱状图\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# 设置全局字体和大小\n",
    "plt.rcParams['font.family'] = 'Arial'  # 设置字体为 Arial\n",
    "plt.rcParams['font.size'] = 24\n",
    "\n",
    "# 从文件上下文中获取的实际指标数据\n",
    "metrics = [f'R$^{2}$', 'MAE', 'MAPE', 'Training Time']\n",
    "\n",
    "# 从文件上下文中提取的实际值\n",
    "gru_values = [0.993, 1675.8, 36.41, 677]  # GRU (模拟训练时间)\n",
    "maxwell_values = [0.991, 622.1, 4.32, 895]  # MLP (模拟训练时间)\n",
    "sls_values = [0.989, 617.15, 4.87, 840]  # PI-MLP (模拟训练时间)\n",
    "fsls_values = [0.988, 624.4, 4.96, 882]  # PI-GRU (模拟训练时间)\n",
    "\n",
    "# 误差棒（模拟值）\n",
    "gru_errors = [0.002, 19, 0.2, 12]\n",
    "maxwell_errors = [0.004, 21, 0.4, 4]\n",
    "sls_errors = [0.003, 15, 0.3, 7]\n",
    "fsls_errors = [0.003, 19, 0.2, 12]\n",
    "\n",
    "# 颜色设置\n",
    "colors = {\n",
    "    'gru': '#377eb8',  # 蓝色\n",
    "    'maxwell': '#4daf4a',  # 绿色\n",
    "    'sls': '#984ea3',  # 紫色\n",
    "    'fsls': '#ff7f00'  # 黄色\n",
    "}\n",
    "\n",
    "# 自定义渐变颜色映射\n",
    "def create_gradient_cmap(color1, color2, gamma=2.0, N=256):\n",
    "    \"\"\"\n",
    "    创建渐变颜色映射\n",
    "    :param color1: 渐变的起点颜色\n",
    "    :param color2: 渐变的终点颜色\n",
    "    :param gamma: 控制渐变的平滑度\n",
    "    :param N: 渐变的分辨率\n",
    "    :return: 渐变颜色映射\n",
    "    \"\"\"\n",
    "    cmap = LinearSegmentedColormap.from_list('custom_cmap', [color1, color2], N=N)\n",
    "    cmap._init()\n",
    "    cmap._lut[:, -1] = np.linspace(0, 1, cmap.N + 3) ** gamma  # 调整透明度\n",
    "    return cmap\n",
    "\n",
    "# 柱状图宽度\n",
    "bar_width = 0.15\n",
    "\n",
    "# 绘图\n",
    "for i, metric in enumerate(metrics):\n",
    "    fig, ax = plt.subplots(figsize=(8, 6), dpi=600)\n",
    "    \n",
    "    # 计算柱状图位置\n",
    "    x = [1, 1.25, 1.5,1.75]  # 3个模型\n",
    "    \n",
    "    # 创建渐变颜色映射\n",
    "    gru_cmap = create_gradient_cmap('lightblue', colors['gru'])\n",
    "    maxwell_cmap = create_gradient_cmap('lightgreen', colors['maxwell'])\n",
    "    sls_cmap = create_gradient_cmap('lavender', colors['sls'])\n",
    "    fsls_cmap = create_gradient_cmap('lightyellow', colors['fsls'])\n",
    "    \n",
    "    # 绘制柱状图\n",
    "    gru_bar = ax.bar(x[0], gru_values[i], width=bar_width, color=gru_cmap(0.8), \n",
    "                    yerr=gru_errors[i], capsize=12, label='DD')\n",
    "    maxwell_bar = ax.bar(x[1], maxwell_values[i], width=bar_width, color=maxwell_cmap(0.8), \n",
    "                      yerr=maxwell_errors[i], capsize=12, label='M')\n",
    "    sls_bar = ax.bar(x[2], sls_values[i], width=bar_width, color=sls_cmap(0.8), \n",
    "                      yerr=sls_errors[i], capsize=12, label='SLS')\n",
    "    fsls_bar = ax.bar(x[3], fsls_values[i], width=bar_width, color=fsls_cmap(0.8), \n",
    "                      yerr=fsls_errors[i], capsize=12, label='FSLS')\n",
    "    \n",
    "    # 显示柱状图数字（格式化为三位有效数字的字符串）\n",
    "    for bar, value, error in zip([gru_bar, maxwell_bar, sls_bar, fsls_bar], \n",
    "                               [gru_values[i], maxwell_values[i], sls_values[i], fsls_values[i]],\n",
    "                               [gru_errors[i], maxwell_errors[i], sls_errors[i], fsls_errors[i]]):\n",
    "        for rect in bar:\n",
    "            height = rect.get_height()\n",
    "            # 将数值显示在柱状图顶部 + 误差值的位置\n",
    "            ax.text(\n",
    "                rect.get_x() + rect.get_width() / 2.0,  # x 位置：柱状图中心\n",
    "                height + error,  # y 位置：柱状图高度 + 误差值\n",
    "                f'{value:.3g}',  # 显示的数值，三位有效数字\n",
    "                ha='center',  # 水平居中\n",
    "                va='bottom',  # 垂直对齐到底部\n",
    "                fontsize=18\n",
    "            )\n",
    "    \n",
    "    # 设置y轴标签\n",
    "    if i == 3:\n",
    "        ax.set_ylabel(metric + ' (s)')\n",
    "    elif i == 2:\n",
    "        ax.set_ylabel(metric + ' (%)')\n",
    "    else:\n",
    "        ax.set_ylabel(metric)\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(['DD', 'M', 'SLS', 'FSLS'])  # x轴标签\n",
    "    \n",
    "    # 调整y轴范围，留出更多空白\n",
    "    max_value = max(gru_values[i], maxwell_values[i], sls_values[i], fsls_values[i])\n",
    "    max_with_error = max_value + max([gru_errors[i], maxwell_errors[i], sls_errors[i], fsls_errors[i]])\n",
    "    ax.set_ylim(0, max_with_error * 1.4)  # 设置y轴上限\n",
    "    \n",
    "\n",
    "    \n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 显示图形\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 绘制算法雷达图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =============== 数据预处理 ===============\n",
    "metrics = ['R$^2$', 'MAE', 'MAPE', 'Cost']\n",
    "models = {\n",
    "  'MLP' : [0.949, 4206.4, 47.02, 450],  # MLP (模拟训练时间)\n",
    "  'PI-MLP' : [0.981, 1728.2, 28.44, 671] , # PI-MLP (模拟训练时间)\n",
    "  'PI-GRU' : [0.991, 622.1, 4.32, 895] ,\n",
    "  'baseline1':[0.9,6000,60,1000] # PI-GRU (模拟训练时间)\n",
    "}\n",
    "\n",
    "# 标准化处理（R²和训练时间正向指标，MAE/MAPE负向指标）\n",
    "def normalize(data, reverse=False):\n",
    "    min_val = min(data)\n",
    "    max_val = max(data)\n",
    "    scaled = [(x - min_val)/(max_val - min_val) for x in data]\n",
    "    return [1-x for x in scaled] if reverse else scaled\n",
    "\n",
    "# 处理各指标\n",
    "r2 = normalize([v[0] for v in models.values()])  # 正向指标\n",
    "mae = normalize([v[1] for v in models.values()], reverse=True)  # 负向指标反向处理\n",
    "mape = normalize([v[2] for v in models.values()], reverse=True)\n",
    "train_time = normalize([v[3] for v in models.values()],reverse=True)  # 负向指标\n",
    "\n",
    "# =============== 雷达图绘制 ===============\n",
    "# 角度计算（闭合处理）\n",
    "num_vars = len(metrics)\n",
    "angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()\n",
    "angles += angles[:1]  # 闭合多边形\n",
    "\n",
    "# 创建画布\n",
    "plt.figure(figsize=(8, 8), dpi=600,facecolor='none')\n",
    "ax = plt.subplot(111, polar=True)\n",
    "ax.patch.set_alpha(0) # 设置子图背景透明\n",
    "# 颜色配置（参考网页1的配色方案）\n",
    "colors = {\n",
    "    'MLP': '#1f77b4',\n",
    "    'PI-MLP': '#ff7f0e',\n",
    "    'PI-GRU': '#2ca02c'\n",
    "}\n",
    "\n",
    "\n",
    "# 绘制每个模型\n",
    "for model, color in colors.items():\n",
    "    values = []\n",
    "    if model == 'MLP': values = [r2[0], mae[0], mape[0], train_time[0]]\n",
    "    elif model == 'PI-MLP': values = [r2[1], mae[1], mape[1], train_time[1]]\n",
    "    elif model == 'PI-GRU': values = [r2[2], mae[2], mape[2], train_time[2]]\n",
    "    \n",
    "    # 数据闭合处理（参考网页3）\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, color=color, linewidth=2, label=model)\n",
    "    ax.fill(angles, values, color=color, alpha=0.1)\n",
    "\n",
    "# =============== 坐标轴设置 ===============\n",
    "# 标签设置（参考网页5）\n",
    "ax.set_theta_offset(np.pi/2)  # 起始角度在顶部\n",
    "ax.set_theta_direction(-1)   # 顺时针方向\n",
    "ax.set_xticks(angles[:-1])\n",
    "\n",
    "# 调整标签位置，避免与雷达图外围线交叉\n",
    "label_positions = {\n",
    "    'R$^2$': [0, 1.1],\n",
    "    'MAE': [np.pi/2, 1.2],  # 向外移动MAE标签\n",
    "    'MAPE': [np.pi, 1.1],\n",
    "    'Cost': [3*np.pi/2, 1.2]  # 向外移动Cost标签\n",
    "}\n",
    "\n",
    "for label, (angle, distance) in zip(metrics, label_positions.values()):\n",
    "    ax.text(angle, distance, label, \n",
    "            ha='center', va='center', \n",
    "            fontsize=24)\n",
    "\n",
    "# 隐藏默认标签\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "# 径向网格线（参考网页10）\n",
    "ax.set_rgrids([0.2, 0.4, 0.6, 0.8], \n",
    "              labels=['20%', '40%', '60%', '80%'],\n",
    "              fontsize=10,\n",
    "              color='grey')\n",
    "\n",
    "# =============== 图例与标题 ===============\n",
    "# 使用自定义图例，放在图表下方，分两行显示\n",
    "# =============== 修改后的图例部分 ===============\n",
    "# 创建图例元素（保持原有代码）\n",
    "legend_elements = []\n",
    "for model, color in colors.items():\n",
    "    legend_elements.append(plt.Line2D([0], [0], marker='o', color='w', \n",
    "                          markerfacecolor=color, markersize=20, label=model))\n",
    "\n",
    "# 单行图例设置\n",
    "legend = ax.legend(\n",
    "    handles=legend_elements,\n",
    "    loc='upper center',          # 基准定位点\n",
    "    bbox_to_anchor=(0.5, -0.1),  # 纵向位置调整（更靠近图表）\n",
    "    ncol=len(colors),            # 列数=模型数量（3）\n",
    "    frameon=False,               # 保持无边框\n",
    "    fontsize=18,\n",
    "    handletextpad=0.5,           # 标签与图标间距\n",
    "    columnspacing=1.5            # 列间间距\n",
    ")\n",
    "# 添加注释文本\n",
    "note_text = \"* Outer edges indicate better performance\"\n",
    "ax.text(0.5, -0.08, note_text, fontsize=14, color='red', ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "\n",
    "# =============== 输出图像 ===============\n",
    "plt.tight_layout()\n",
    "plt.savefig('pic/leida-laos.pdf', bbox_inches='tight',transparent=True)  # 矢量格式输出（参考网页7）\n",
    "plt.show()\n",
    "# =============== 方案三：极坐标辅助刻度系统 ===============\n",
    "# 理论最优值配置（标准化后的最优值为1）\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PINN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
