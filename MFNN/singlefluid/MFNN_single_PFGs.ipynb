{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单流体嵌入网络的PBFs聚合物"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import random, genfromtxt\n",
    "from IPython.display import display\n",
    "from matplotlib import rc\n",
    "from matplotlib.pyplot import figure\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.ticker as mticker\n",
    "# 使用MinMaxScaler进行归一化\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置数据类型\n",
    "DTYPE = torch.float32\n",
    "\n",
    "# 设置随机种子\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "def load_and_process_data(file_path, feature_cols, target_col, sheet_name=None, sample_idx=None, \n",
    "                          test_filter_col=None, test_filter_value=None, log_cols=None):\n",
    "    \"\"\"\n",
    "    加载并处理数据\n",
    "    \n",
    "    参数:\n",
    "    file_path: 数据文件路径\n",
    "    feature_cols: 特征列名列表\n",
    "    target_col: 目标列名\n",
    "    sheet_name: Excel表格的sheet名称\n",
    "    sample_idx: 如果有多个sheet，指定使用第几个sheet的索引\n",
    "    test_filter_col: 用于筛选测试集的列名\n",
    "    test_filter_value: 测试集筛选值\n",
    "    log_cols: 需要进行对数变换的列索引列表\n",
    "    \n",
    "    返回:\n",
    "    处理后的数据和归一化器\n",
    "    \"\"\"\n",
    "    # 读取数据\n",
    "    if sheet_name is not None:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    else:\n",
    "        df_all = pd.read_excel(file_path, sheet_name=None)\n",
    "        if sample_idx is not None:\n",
    "            data_list = [[k, v] for k, v in df_all.items()]\n",
    "            df = data_list[sample_idx][1]\n",
    "        else:\n",
    "            raise ValueError(\"必须提供sheet_name或sample_idx\")\n",
    "    \n",
    "    # 删除缺失值\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # 分离测试集（如果需要）\n",
    "    test_df = None\n",
    "    if test_filter_col is not None and test_filter_value is not None:\n",
    "        test_df = df[df[test_filter_col] == test_filter_value].copy()\n",
    "        df = df[df[test_filter_col] != test_filter_value].copy()\n",
    "    \n",
    "    # 提取特征和目标\n",
    "    X = df[feature_cols].values\n",
    "    y = df[target_col].values.reshape(-1, 1)\n",
    "    \n",
    "    # 对数变换\n",
    "    if log_cols is not None:\n",
    "        for col_idx in log_cols:\n",
    "            X[:, col_idx] = np.log10(X[:, col_idx])\n",
    "    \n",
    "    # 归一化\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "    \n",
    "    X_normalized = scaler_X.fit_transform(X)\n",
    "    y_normalized = scaler_y.fit_transform(y)\n",
    "    \n",
    "    # 转换为PyTorch张量\n",
    "    X_tensor = torch.tensor(X_normalized, dtype=DTYPE)\n",
    "    y_tensor = torch.tensor(y_normalized, dtype=DTYPE)\n",
    "    \n",
    "    # 处理测试集\n",
    "    X_test_tensor, y_test_tensor = None, None\n",
    "    if test_df is not None:\n",
    "        X_test = test_df[feature_cols].values\n",
    "        y_test = test_df[target_col].values.reshape(-1, 1)\n",
    "        \n",
    "        # 对数变换测试集\n",
    "        if log_cols is not None:\n",
    "            for col_idx in log_cols:\n",
    "                X_test[:, col_idx] = np.log10(X_test[:, col_idx])\n",
    "        \n",
    "        # 使用训练集的归一化器对测试集进行归一化\n",
    "        X_test_normalized = scaler_X.transform(X_test)\n",
    "        y_test_normalized = scaler_y.transform(y_test)\n",
    "        \n",
    "        # 转换测试集为PyTorch张量\n",
    "        X_test_tensor = torch.tensor(X_test_normalized, dtype=DTYPE)\n",
    "        y_test_tensor = torch.tensor(y_test_normalized, dtype=DTYPE)\n",
    "    \n",
    "    return X_tensor, y_tensor, X_test_tensor, y_test_tensor, scaler_X, scaler_y\n",
    "\n",
    "# 定义特征列和目标列\n",
    "feature_cols = ['DP', 'Mn', 'PDI', 'AngFreq']\n",
    "target_col = 'LossFactor'\n",
    "freq_col_idx = 3  # AngFreq列的索引\n",
    "\n",
    "# 加载高保真数据\n",
    "X_data_HF, y_data_HF, X_test_tensor, y_test_tensor, scaler_X_hf, scaler_y_hf = load_and_process_data(\n",
    "    file_path='Data/Data_HF.xlsx',\n",
    "    feature_cols=feature_cols,\n",
    "    target_col=target_col,\n",
    "    sample_idx=1,\n",
    "    test_filter_col='DP',\n",
    "    test_filter_value=162,\n",
    "    log_cols=[freq_col_idx]\n",
    ")\n",
    "\n",
    "# 加载低保真数据\n",
    "X_lf_tensor, y_lf_tensor, _, _, scaler_X_lf, scaler_y_lf = load_and_process_data(\n",
    "    file_path='Data/Data_LF_S_PFGs.xlsx',\n",
    "    feature_cols=feature_cols,\n",
    "    target_col=target_col,\n",
    "    sheet_name='Sheet1',\n",
    "    test_filter_col='DP',\n",
    "    test_filter_value=162,\n",
    "    log_cols=[freq_col_idx]\n",
    ")\n",
    "\n",
    "# 定义模型\n",
    "in_dim, out_dim = 4, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络的类\n",
    "class PINN_NeuralNet(nn.Module):\n",
    "    \"\"\" Set basic architecture of the PINN model.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim=0,\n",
    "                 output_dim=1,  # 默认输出维度为1\n",
    "                 num_hidden_layers=4, \n",
    "                 num_neurons_per_layer=20,\n",
    "                 activation='tanh',\n",
    "                 kernel_initializer='glorot_normal',\n",
    "                 **kwargs):\n",
    "        super(PINN_NeuralNet, self).__init__()\n",
    "\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # 添加输入层\n",
    "        self.input_layer = nn.Linear(input_dim, num_neurons_per_layer)\n",
    "        \n",
    "        # 添加其他隐藏层\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(num_hidden_layers):\n",
    "            self.hidden_layers.append(nn.Linear(num_neurons_per_layer, num_neurons_per_layer))\n",
    "        \n",
    "        # 添加输出层\n",
    "        self.out = nn.Linear(num_neurons_per_layer, output_dim)\n",
    "        # 设置激活函数\n",
    "        if activation == 'tanh':\n",
    "            self.activation = torch.tanh\n",
    "        elif activation == 'relu':\n",
    "            self.activation = F.relu6\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = torch.sigmoid\n",
    "        elif activation == 'linear':\n",
    "            self.activation = None\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "        \n",
    "        # 初始化权重\n",
    "        if kernel_initializer == 'glorot_normal':\n",
    "            nn.init.xavier_normal_(self.input_layer.weight)\n",
    "            for hidden_layer in self.hidden_layers:\n",
    "                nn.init.xavier_normal_(hidden_layer.weight)\n",
    "            nn.init.xavier_normal_(self.out.weight)\n",
    "        elif kernel_initializer == 'glorot_uniform':\n",
    "            nn.init.xavier_uniform_(self.input_layer.weight)\n",
    "            for hidden_layer in self.hidden_layers:\n",
    "                nn.init.xavier_uniform_(hidden_layer.weight)\n",
    "            nn.init.xavier_uniform_(self.out.weight)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported kernel initializer\")\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        # 进入输入层\n",
    "        Z = self.input_layer(X)\n",
    "        \n",
    "        # 通过隐藏层\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            Z = hidden_layer(Z)\n",
    "            if self.activation is not None:\n",
    "                Z = self.activation(Z)\n",
    "        # 通过输出层输出\n",
    "        Z = self.out(Z)\n",
    "        \n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络处理器类\n",
    "class PINNSolver():\n",
    "\n",
    "    # 类属性定义\n",
    "    def __init__(self, model_HF_nl, model_HF_l,model_LF):\n",
    "        self.model_LF = model_LF # 低保真模型\n",
    "        self.model_HF_nl = model_HF_nl # 高保真非线性模型\n",
    "        self.model_HF_l = model_HF_l # 高保真线性模型\n",
    "\n",
    "        self.hist =  [[], []] # loss历史列表,0:total loss ;1:LF loss\n",
    "        self.iter = 0 # 迭代次数\n",
    "        self.last_n_losses = [] # 前损失列表\n",
    "\n",
    "    # 更新损失列表   \n",
    "    def update_last_n_losses(self, loss):\n",
    "        self.last_n_losses.append(loss)\n",
    "        if len(self.last_n_losses) > 20:\n",
    "            self.last_n_losses.pop(0)\n",
    "\n",
    "    # 计算最大相对误差        \n",
    "    def ES(self):\n",
    "        if len(self.last_n_losses) < 20:\n",
    "            return 100  # a large number\n",
    "\n",
    "        current_loss = self.last_n_losses[-1]\n",
    "        max_relative_error = 100.*max([abs(current_loss - loss) / current_loss for loss in self.last_n_losses[:-1]])\n",
    "        return max_relative_error\n",
    "    \n",
    "    # 计算loss，模型核心\n",
    "    def loss_fn(self, X_data_HF, y_data_HF,X_lf_tensor ,y_lf_tensor):    \n",
    "        y_pred_LF = self.model_LF(X_lf_tensor)\n",
    "\n",
    "        y_pred_LF_HF = self.model_LF(X_data_HF)\n",
    "   \n",
    "        # 将X_data_HF和y_pred_LF_HF在特征维度上拼接\n",
    "        X_combined = torch.cat([X_data_HF, y_pred_LF_HF], dim=1)\n",
    "\n",
    "        y_pred_HF_nl = self.model_HF_nl(X_combined)\n",
    "        y_pred_HF_l = self.model_HF_l(X_combined)\n",
    "\n",
    "        y_pred_HF = y_pred_HF_nl + y_pred_HF_l\n",
    "\n",
    "        Loss_L2 = 1e-5 * sum(torch.sum(w_**2) for w_ in self.model_HF_nl.parameters())\n",
    "        Loss_L2 += 1e-5 * sum(torch.sum(w_**2) for w_ in self.model_HF_l.parameters())\n",
    "        Loss_L2 += 1e-5 * sum(torch.sum(w_**2) for w_ in self.model_LF.parameters())\n",
    "        Loss_data_LF = torch.mean((y_lf_tensor - y_pred_LF)**2)\n",
    "\n",
    "        Loss_data_HF = torch.mean((y_data_HF - y_pred_HF)**2)+Loss_L2\n",
    "        # Total_loss=Loss_data_LF+Loss_data_HF\n",
    "        Total_loss=Loss_data_HF\n",
    "        return Total_loss,Loss_data_LF\n",
    "    # 训练核心函数，包括loss计算梯度计算和反向传播\n",
    "    def solve_with_PyTorch_optimizer(self, optimizer,data,scheduler,N=1001):\n",
    "        \"\"\"This method performs a gradient descent type optimization.\"\"\"        \n",
    "        for i in range(N):\n",
    "            # 梯度清0\n",
    "            optimizer.zero_grad()\n",
    "            # 计算loss          \n",
    "            loss,loss_lf = self.loss_fn(data[0], data[1],data[2],data[3])\n",
    "            # 反向传播计算梯度\n",
    "            loss.backward()\n",
    "            # 根据loss调度学习率\n",
    "            scheduler.step(loss)\n",
    "            # 反向传播更新权重和偏置\n",
    "            optimizer.step()\n",
    "\n",
    "            # 记录loss并计算相对误差\n",
    "            self.current_loss = loss.item()\n",
    "            self.lf_loss=loss_lf.item()\n",
    "           \n",
    "            self.max_relative_error = self.ES()\n",
    "            self.callback(self.max_relative_error,N)  # Pass max_relative_error to the callback function\n",
    "            self.update_last_n_losses(self.current_loss)\n",
    "\n",
    "            # 早停机制\n",
    "            if self.max_relative_error < 2e-3: # in %\n",
    "                print('Early stopping... \\nIt {:05,d}: Loss = {:10.4e}, Max. rel. error = {} %'.format(self.iter,\n",
    "                                                             self.current_loss,\n",
    "                                                            np.round(self.max_relative_error, 3)))\n",
    "                break\n",
    "\n",
    "    # 打印loss    \n",
    "    def callback(self, xr=None,N=1001):\n",
    "        if self.iter % 500 == 0:\n",
    "            print('It {:05,d}: Loss = {:10.4e}, Max. rel. error = {} %'.format(self.iter,\n",
    "                                                             self.current_loss,\n",
    "                                                            np.round(self.max_relative_error, 2)))\n",
    "        self.hist[0].append(self.current_loss)\n",
    "        self.hist[1].append(self.lf_loss)\n",
    "        self.iter+=1\n",
    "    \n",
    "    def plot_loss_history(self, ax=None):\n",
    "        if not ax:\n",
    "            fig = plt.figure(figsize=(7, 5))\n",
    "            ax = fig.add_subplot(111)\n",
    "\n",
    "        # 绘制训练集损失曲线\n",
    "        ax.semilogy(range(len(self.hist[0])), self.hist[0], 'b-', label='Training Loss')\n",
    "        \n",
    "        # 绘制验证集损失曲线\n",
    "        ax.semilogy(range(len(self.hist[1])), self.hist[1], 'g-', label='LF Loss')\n",
    "\n",
    "        ax.set_xlabel('$n_{epoch}$')\n",
    "        ax.set_ylabel('$loss$')\n",
    "        ax.xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, pos: f'{int(x):,}'))\n",
    "        ax.legend()  # 添加图例\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "model_LF = PINN_NeuralNet(input_dim=in_dim,\n",
    "                         output_dim=out_dim,\n",
    "                         num_hidden_layers=4,\n",
    "                         num_neurons_per_layer=64,\n",
    "                         activation='relu'\n",
    "                         )\n",
    "model_HF_nl = PINN_NeuralNet(input_dim=in_dim+out_dim,\n",
    "                             output_dim=out_dim,\n",
    "                             num_hidden_layers=4,\n",
    "                             num_neurons_per_layer=64,\n",
    "                             activation='relu')\n",
    "model_HF_l = PINN_NeuralNet(input_dim=in_dim+out_dim,\n",
    "                            output_dim=out_dim,\n",
    "                            num_hidden_layers=1,\n",
    "                            num_neurons_per_layer=10,\n",
    "                            activation='linear')\n",
    "\n",
    "# 初始化 PINNSolver\n",
    "solver = PINNSolver(model_HF_nl, model_HF_l,model_LF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义学习率调度器\n",
    "lr = 1e-3\n",
    "optimizer = optim.Adam(list(model_HF_nl.parameters()) + list(model_HF_l.parameters())+list(model_LF.parameters()), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=10, verbose=True)\n",
    "# 定义训练模式\n",
    "mode = 'PyTorch_optimizer'\n",
    "N = int(4000) + 1  # 训练迭代次数\n",
    "\n",
    "try:\n",
    "    runtime\n",
    "except NameError:\n",
    "    runtime = 0.\n",
    "\n",
    "if mode == 'PyTorch_optimizer':\n",
    "    try:\n",
    "        t0 = time()\n",
    "        solver.solve_with_PyTorch_optimizer(optimizer, [X_data_HF,y_data_HF,X_lf_tensor,y_lf_tensor],scheduler,N=N)\n",
    "        runtime += (time() - t0) / 60.\n",
    "        print('\\nRuntime: {:.3f} minutes'.format(runtime))\n",
    "    except KeyboardInterrupt:\n",
    "        runtime += (time() - t0) / 60.\n",
    "        print('\\nRuntime: {:.3f} minutes'.format(runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver.plot_loss_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置字体为Arial\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rc('font', size=24)\n",
    "plt.rc('axes', titlesize=24)\n",
    "plt.rc('axes', labelsize=24)\n",
    "plt.rc('xtick', labelsize=24)\n",
    "plt.rc('ytick', labelsize=24)\n",
    "plt.rc('legend', fontsize=18)\n",
    "plt.rc('figure', titlesize=24)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6),dpi=600)\n",
    "\n",
    "# 使用模型预测\n",
    "y_lf = solver.model_LF(X_test_tensor)\n",
    "X_pred_hf = torch.cat([X_test_tensor, y_lf], dim=1)\n",
    "y_pred = solver.model_HF_nl(X_pred_hf) + solver.model_HF_l(X_pred_hf)\n",
    "y_pred_denorm = scaler_y_hf.inverse_transform(y_pred.detach().numpy())\n",
    "\n",
    "# 对预测数据进行排序以绘制平滑曲线\n",
    "sort_idx = np.argsort(X_test[:,3])\n",
    "x_sorted = X_test[sort_idx,3]\n",
    "y_pred_sorted = y_pred_denorm[sort_idx]\n",
    "\n",
    "# 绘制预测值和实验值的对比\n",
    "ax.scatter(10**X_test[:,3], y_test, color='blue', marker='o', s=50, label='Test Data')\n",
    "ax.plot(10**x_sorted, y_pred_sorted, color='black', linewidth=2, label='Prediction')\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('$tan\\delta$')\n",
    "ax.set_xlabel('$\\omega$ $\\mathrm{[rad/s]}$')\n",
    "ax.legend(frameon=False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# 设置输出为SVG格式\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入评估指标所需的库\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 计算评估指标\n",
    "# R2 - 决定系数\n",
    "r2 = r2_score(y_test, y_pred_denorm)\n",
    "\n",
    "# MAE - 平均绝对误差\n",
    "mae = mean_absolute_error(y_test, y_pred_denorm)\n",
    "\n",
    "# RMSE - 均方根误差\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_denorm))\n",
    "\n",
    "# MAPE - 平均绝对百分比误差\n",
    "mape = np.mean(np.abs((y_test - y_pred_denorm) / y_test)) * 100\n",
    "\n",
    "# 打印评估指标\n",
    "print(\"模型预测性能评估指标:\")\n",
    "print(f\"R² (决定系数): {r2:.4f}\")\n",
    "print(f\"MAE (平均绝对误差): {mae:.4f}\")\n",
    "print(f\"RMSE (均方根误差): {rmse:.4f}\")\n",
    "print(f\"MAPE (平均绝对百分比误差): {mape:.2f}%\")\n",
    "\n",
    "# 创建一个包含所有指标的表格\n",
    "from tabulate import tabulate\n",
    "metrics_table = [\n",
    "    [\"指标\", \"值\"],\n",
    "    [\"R²\", f\"{r2:.4f}\"],\n",
    "    [\"MAE\", f\"{mae:.4f}\"],\n",
    "    [\"RMSE\", f\"{rmse:.4f}\"],\n",
    "    [\"MAPE\", f\"{mape:.2f}%\"]\n",
    "]\n",
    "print(\"\\n\" + tabulate(metrics_table, headers=\"firstrow\", tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型的状态字典\n",
    "# torch.save(model_HF_nl.state_dict(), 'model/model_nl_pinn_pbfs_lossf.pth')\n",
    "# torch.save(model_HF_l.state_dict(), 'model/model_l_pinn_pbfs_lossf.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R²     | 0.9755 |\n",
    "+--------+--------+\n",
    "| MAE    | 0.0879 |\n",
    "+--------+--------+\n",
    "| RMSE   | 0.1096 |\n",
    "+--------+--------+\n",
    "| MAPE   | 14.03% "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PINN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
